{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-family",
   "metadata": {},
   "source": [
    "# morse alphabet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorseAlphabet():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.letters = '''A  .- \t B  -... \t C  -.-. \t D  -..\n",
    "        E  . \t F  ..-. \t G  --. \t H  ....\n",
    "        I  .. \t J  .--- \t K  -.- \t L  .-..\n",
    "        M  -- \t N  -. \t O  --- \t P  .--.\n",
    "        Q  --.- \t R  .-. \t S  ... \t T  -\n",
    "        U  ..- \t V  ...- \t W  .-- \t X  -..-\n",
    "        Y  -.-- \t Z  --..'''\n",
    "        self.encoded_letters_map = self.__generate_alphabet_map()\n",
    "        self.encoded_letters = list(self.encoded_letters_map.values())\n",
    "       \n",
    "    def get_encoded_letters(self):\n",
    "        return self.encoded_letters\n",
    "        \n",
    "    def get_encoded_letters_map(self):\n",
    "        return self.encoded_letters_map\n",
    "        \n",
    "    def encode(self, letter):\n",
    "        return self.encoded_letters_map[letter]\n",
    "        \n",
    "    def __generate_alphabet_map(self):\n",
    "        key = None\n",
    "        alphabet_map = {}\n",
    "        for value in self.letters.split():\n",
    "            if not key is None:\n",
    "                alphabet_map[key] = value\n",
    "                key = None\n",
    "            else:\n",
    "                key = value  \n",
    "        return alphabet_map     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse = MorseAlphabet()\n",
    "\n",
    "assert morse.encode('D') == '-..'\n",
    "assert '-..' in morse.get_encoded_letters()\n",
    "assert morse.get_encoded_letters_map()['D'] == '-..'\n",
    "\n",
    "assert morse.encode('I') == '..'\n",
    "assert '.---' in morse.get_encoded_letters()\n",
    "assert morse.get_encoded_letters_map()['I'] == '..'\n",
    "\n",
    "assert morse.encode('J') == '.---'\n",
    "assert '.---' in morse.get_encoded_letters()\n",
    "assert morse.get_encoded_letters_map()['J'] == '.---'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEncoder():\n",
    "    def __init__(self, sep='', alphabet=None):\n",
    "        self.encoded_dict = {}\n",
    "        self.encoded_partial_dict = {}\n",
    "        self.sep = sep\n",
    "        if alphabet:\n",
    "            self.alphabet = alphabet \n",
    "        else:\n",
    "            self.alphabet = MorseAlphabet()\n",
    "        \n",
    "    def get_alphabet(self):\n",
    "        return self.alphabet\n",
    "        \n",
    "    def get_list(self):\n",
    "        return list(self.encoded_dict.keys())\n",
    "        \n",
    "    def get_dict(self):\n",
    "        return self.encoded_dict\n",
    "        \n",
    "    def get_partial_dict(self):\n",
    "        return self.encoded_partial_dict\n",
    "        \n",
    "    def add_word_list(self, words):\n",
    "        [self.add_word(w) for w in words]\n",
    "        \n",
    "    def add_word(self, word):\n",
    "        alphabet_map = self.alphabet.get_encoded_letters_map()\n",
    "        letters = []\n",
    "        for letter in word: \n",
    "            letters.append(alphabet_map[letter])\n",
    "        encoded_word = self.sep.join(letters)\n",
    "        for l in range(len(letters)): \n",
    "            partial_word = self.sep.join(letters[0:l])\n",
    "            if partial_word in self.encoded_partial_dict: \n",
    "                if encoded_word not in self.encoded_partial_dict[partial_word]:\n",
    "                    self.encoded_partial_dict[partial_word].append(encoded_word)\n",
    "            else: \n",
    "                self.encoded_partial_dict[partial_word] = [encoded_word]\n",
    "        if encoded_word in self.encoded_dict: self.encoded_dict[encoded_word] += 1\n",
    "        else: self.encoded_dict[encoded_word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = WordEncoder()\n",
    "\n",
    "encoder.add_word('HTE')\n",
    "encoded_dict = encoder.get_dict()\n",
    "assert encoded_dict['....-.'] == 1\n",
    "encoder.add_word('HTE')\n",
    "encoded_dict = encoder.get_dict()\n",
    "assert encoded_dict['....-.'] == 2\n",
    "assert len(encoder.get_list()) == 1\n",
    "\n",
    "\n",
    "encoder = WordEncoder(sep='|', alphabet=morse)\n",
    "encoder.add_word('HTE')\n",
    "encoded_dict = encoder.get_dict()\n",
    "assert encoded_dict['....|-|.'] == 1\n",
    "\n",
    "encoder = WordEncoder()\n",
    "encoder.add_word_list(['HTE', 'EE'])\n",
    "encoded_dict = encoder.get_dict()\n",
    "assert encoded_dict['....-.'] == 1\n",
    "assert encoded_dict['..'] == 1\n",
    "assert len(encoder.get_list()) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-potato",
   "metadata": {},
   "source": [
    "#### version 5 6 \n",
    "- basic reducer with remaining\n",
    "- replace list manipulations with node -> still bumpinto the reccursion  limitation\n",
    "- replace reccursion with command pattern -> still too long \n",
    "- options object - keep track of solved positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context():\n",
    "    def __init__(self, word_encoder=None): \n",
    "        if word_encoder:\n",
    "            self.word_encoder = word_encoder            \n",
    "        else:\n",
    "            self.word_encoder = WordEncoder()\n",
    "    \n",
    "    def get_sentence(self):\n",
    "        return self.sentence    \n",
    "    \n",
    "    def get_encoder(self):\n",
    "        return self.word_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, segment, duplicates=1, parent=None):\n",
    "        self.parent = parent\n",
    "        self.segment = segment\n",
    "        self.duplicates = duplicates\n",
    "        self.length = len(segment)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'<Node>{self.segment}'\n",
    "        \n",
    "    def get_segment(self):\n",
    "        return self.segment\n",
    "    \n",
    "    def get_duplicates(self):\n",
    "        return self.duplicates\n",
    "        \n",
    "    def get_sequence(self, sep='|'):\n",
    "        sequence = [self.segment]\n",
    "        parent = self.parent\n",
    "        while parent:\n",
    "            sequence.append(parent.segment)\n",
    "            parent = parent.parent\n",
    "        sequence.reverse()\n",
    "        text = sep.join(sequence)\n",
    "        return text\n",
    "    \n",
    "    def get_length_sequence(self):\n",
    "        sequence = [self.length]\n",
    "        parent = self.parent\n",
    "        while parent:\n",
    "            sequence.append(parent.length)\n",
    "            parent = parent.parent\n",
    "        sequence.reverse()    \n",
    "        return sequence\n",
    "    \n",
    "    def get_sum_length_sequence(self):\n",
    "        return sum(self.get_length_sequence())    \n",
    "    \n",
    "    def get_nb_options(self):\n",
    "        nb_options = self.duplicates\n",
    "        parent = self.parent\n",
    "        while parent:\n",
    "            nb_options *= parent.duplicates\n",
    "            parent = parent.parent\n",
    "        return nb_options\n",
    "    \n",
    "    def append(self, node):\n",
    "         node.parent = self\n",
    "        \n",
    "    def get_sequence_start(self):\n",
    "        node = self\n",
    "        while node.parent:\n",
    "            node = node.parent\n",
    "        return node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_1 = Node('..')\n",
    "print(node_1.get_sequence())\n",
    "assert node_1.get_sequence() == '..'\n",
    "assert node_1.get_sum_length_sequence() == 2\n",
    "\n",
    "print(\"nodes\")\n",
    "node_2 = Node('-', parent=node_1)\n",
    "node_3 = Node('.--', parent=node_2)\n",
    "assert node_3.get_sequence() == '..|-|.--'\n",
    "assert node_3.get_sum_length_sequence() == 6\n",
    "assert node_2.get_sum_length_sequence() == 3\n",
    "\n",
    "print(\"append\")\n",
    "node_4 = Node('.')\n",
    "node_3.append(node_4)\n",
    "assert node_4.get_sequence() == '..|-|.--|.'\n",
    "\n",
    "print(\"start\")\n",
    "origin = node_4.get_sequence_start()\n",
    "assert origin.get_sequence() == '..'\n",
    "\n",
    "print(\"options\")\n",
    "node_5 = Node('--', parent=node_4, duplicates=2)\n",
    "print(node_5.get_nb_options())\n",
    "assert node_5.get_nb_options() == 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Command():\n",
    "    def __init__(self, level, pos, last_node, remaining):\n",
    "        self.pos = pos\n",
    "        self.level = level\n",
    "        self.last_node = last_node\n",
    "        self.remaining = remaining\n",
    "        self.done = True if not remaining else False\n",
    "    \n",
    "    def get_level(self):\n",
    "        return self.level     \n",
    "    def get_pos(self):\n",
    "        return self.pos  \n",
    "    def get_last_node(self):\n",
    "        return self.last_node     \n",
    "    def get_remaining(self):\n",
    "        return self.remaining    \n",
    "    def get_done(self):\n",
    "        return self.done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import functools\n",
    "\n",
    "class Options():\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.slots = [{} for i in range(size)]\n",
    "            \n",
    "    def append(self, pos, node) -> bool:\n",
    "        added = False\n",
    "        if node.get_segment() not in self.slots[pos]:\n",
    "            # avoid counting the same segment twice - will prune\n",
    "            self.slots[pos][node.get_segment()] = node.get_duplicates()\n",
    "            added = True\n",
    "        return added\n",
    "        \n",
    "    def count(self):\n",
    "        # duplicates multiply\n",
    "        # nb nodes in slot add up duplicates\n",
    "        slots_count = [sum(slot.values()) for slot in self.slots]\n",
    "        total = functools.reduce(operator.mul, [n for n in slots_count if n>0], 1)\n",
    "        return total\n",
    "        \n",
    "    def pretty_print(self):\n",
    "        text = ''\n",
    "        [print(slot) for slot in self.slots]\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [ 'ABC', 'DEF', 'AB', 'CD', 'EF']\n",
    "sentence = 'ABCDEF'\n",
    "options = Options(len(sentence))\n",
    "options.append(0, Node('ABC'))\n",
    "options.append(3, Node('DEF'))\n",
    "options.append(0, Node('AB'))\n",
    "options.append(2, Node('CD'))\n",
    "options.append(4, Node('EF'))\n",
    "print(options.pretty_print())\n",
    "assert options.slots[0] == {'ABC': 1, 'AB': 1}\n",
    "\n",
    "assert options.count() == 2 # 'ABC' 'DEF', 'AB' 'CD' 'EF'\n",
    "\n",
    "res = options.append(4, Node('EF'))\n",
    "assert res is False\n",
    "assert options.slots[4] == {'EF': 1}\n",
    "\n",
    "options = Options(len(sentence))\n",
    "options.append(0, Node('ABC', duplicates=2)) # lets predent ABC actually stands for 2 diffenent encoded words\n",
    "options.append(3, Node('DEF'))\n",
    "options.append(0, Node('AB'))\n",
    "options.append(2, Node('CD'))\n",
    "options.append(4, Node('EF'))\n",
    "\n",
    "assert options.count() == 3 # 'ABC'*2 'DEF', 'AB' 'CD' 'EF'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDecoder():\n",
    "    def __init__(self, context):\n",
    "        self.context = context\n",
    "        self.sentence = None\n",
    "        self.valid_words_map = context.get_encoder().get_dict()\n",
    "        self.options = None\n",
    "        #self.partial_words_map  = context.get_encoder().get_partial_dict()\n",
    "        #self.morse_letters = context.get_encoder().get_alphabet().get_encoded_letters()\n",
    "\n",
    "    def screen_words(self, encoded_words_map):\n",
    "        valid_encoded_words_maps = { k:v for k,v in encoded_words_map.items() if self.sentence.find(k)>=0}\n",
    "        print(f'nb possible words {len(valid_encoded_words_maps.keys())}')\n",
    "        return valid_encoded_words_maps\n",
    "   \n",
    "    def decode(self, sentence):\n",
    "        # dumb cases\n",
    "        if len(sentence) == 0: \n",
    "            print('empty sentence')\n",
    "            return 0      \n",
    "        \n",
    "        self.sentence = sentence\n",
    "        \n",
    "        self.valid_words_map = self.screen_words(self.valid_words_map)\n",
    "        if len(self.valid_words_map.keys()) == 0: \n",
    "            print('empty words')\n",
    "            return 0\n",
    "        #print(f'valid_words_map {self.valid_words_map}')\n",
    "\n",
    "        self.options = Options(len(sentence))\n",
    "        start_command = Command(0, 0, None, self.sentence)\n",
    "        commands = [start_command]\n",
    "        nb_options = 0\n",
    "        while commands:\n",
    "            commands, nb_options = self.decode_loop(commands, nb_options)\n",
    "            \n",
    "        return nb_options\n",
    "\n",
    "    def decode_loop(self, commands, last_nb_options):\n",
    "        nb_options = last_nb_options\n",
    "        new_commands = []\n",
    "        new_sequences = {}\n",
    "        for command in commands:\n",
    "            level = command.get_level()\n",
    "            last_node = command.get_last_node()\n",
    "            remaining = command.get_remaining()\n",
    "            pos = command.get_pos()\n",
    "            done = command.get_done()\n",
    "            #if last_node:\n",
    "            #   print(f'cmdi.{level} current:{last_node.get_sequence()} remaining:{remaining} done:{done}')\n",
    "            \n",
    "            if command.get_done(): \n",
    "                nb_options_for_sequence = last_node.get_nb_options()  \n",
    "                print(f'done.{level} current:{last_node.get_sequence()} remaining:{remaining} nb:{nb_options_for_sequence}')\n",
    "                nb_options += nb_options_for_sequence \n",
    "                continue\n",
    "                 \n",
    "            for word, duplicates in self.valid_words_map.items():\n",
    "                if remaining.startswith(word):\n",
    "                    new_last_node = Node(word, duplicates=duplicates)\n",
    "                    if last_node: \n",
    "                        last_node.append(new_last_node)\n",
    "                        #il faut trouver un moyen d'oliùoner les mots déjatrouvés comme ça\n",
    "                        #ndex de szq de nodes\n",
    "                        #new_sequences[new_last_node.get_sequence(sep='')] = new_last_node.get_nb_options() \n",
    "                    print(f'word.{level} all:{new_last_node.get_sequence()} word:{word} duplicates:{duplicates}')\n",
    "                   \n",
    "                    is_new = self.options.append(pos, new_last_node)\n",
    "                    \n",
    "                    i = len(word)\n",
    "                    new_remaining = str(remaining[i:])\n",
    "                    if new_last_node.get_sum_length_sequence() + len(new_remaining) != len(self.sentence):\n",
    "                        print(f'word.{level} diff {new_last_node.get_sum_length_sequence()}+{len(new_remaining)}={len(self.sentence)}')\n",
    "                    \n",
    "                    new_commands.append(Command(level+1, i, new_last_node, new_remaining))\n",
    "        \n",
    "        #print(f'loop. nb_options:{nb_options} new_commands:{len(new_commands)}')\n",
    "        self.valid_words_map.update(new_sequences)\n",
    "\n",
    "        return new_commands, nb_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_runner(target_sentence, words):\n",
    "    print(f'nb words {len(words)}')\n",
    "             \n",
    "    word_encoder = WordEncoder()\n",
    "    word_encoder.add_word_list(words)\n",
    "    print(f'encoded words {word_encoder.get_dict()}')\n",
    "    print(f'nb encoded words {len(word_encoder.get_dict())}')\n",
    "\n",
    "    context = Context(word_encoder=word_encoder)\n",
    "    decoder = SentenceDecoder(context)\n",
    "    res = decoder.decode(target_sentence)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-agency",
   "metadata": {},
   "source": [
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-subcommittee",
   "metadata": {},
   "source": [
    "# unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-mixer",
   "metadata": {},
   "source": [
    "### empty sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence = '' \n",
    "words = ['SE', 'T', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-member",
   "metadata": {},
   "source": [
    "### empty words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence = '-' # T \n",
    "words = [] \n",
    "\n",
    "res = count_runner(morse_sentence, words)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-england",
   "metadata": {},
   "source": [
    "### one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence = '-' # T \n",
    "words = ['T'] \n",
    "\n",
    "res = count_runner(morse_sentence, words)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence = '--' # T \n",
    "words = ['T', 'X', 'M'] \n",
    "\n",
    "res = count_runner(morse_sentence, words)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-eagle",
   "metadata": {},
   "source": [
    "### One letter - one option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-agency",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence = '-' # T\n",
    "words = ['SE', 'T', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1 # T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-advertising",
   "metadata": {},
   "source": [
    "### very few words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence = '-.-.' # TETE\n",
    "words = ['TE'] \n",
    "\n",
    "res = count_runner(morse_sentence, words)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1 # TE TE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence = '-.-.' # TETE\n",
    "words = ['T','E'] \n",
    "\n",
    "res = count_runner(morse_sentence, words)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1 # TE TE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-efficiency",
   "metadata": {},
   "source": [
    "### short message - multiple options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence = '....' # E . I .. S ... H ....\n",
    "words = ['EIE', 'SE', 'ES', 'H', 'L', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 4 # EIE, ES, H, SE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-cooling",
   "metadata": {},
   "source": [
    "### no match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence = '....' # E . I .. S ... H ....\n",
    "words = ['S', 'L', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 0 # no match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-connecticut",
   "metadata": {},
   "source": [
    "### short message - multiple options with permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence = '.....' # confusion EH/HE\n",
    "words = ['HEL', 'HE', 'EH', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 2 # HE, EH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-biography",
   "metadata": {},
   "source": [
    "### short message - one option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence = '......-..' # HEL single option\n",
    "words = ['HEL', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1 # HEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-mount",
   "metadata": {},
   "source": [
    "### short message - multiple options with partial match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence = '......-..' # HEL or HE L\n",
    "words = ['HEL', 'HE', 'L', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 2 # HEL, HE L  -- fix stops when HE L is found and never reach HEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-example",
   "metadata": {},
   "source": [
    "### short message - multiple options with partial match and permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-winter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "morse_sentence = '......-..' # HEL with confusion EH/HE\n",
    "words = ['HEL', 'HE', 'EH', 'L', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 3 # HEL, HE L, EH L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-council",
   "metadata": {},
   "source": [
    "### short sample message - multiple options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence = '......-...-..---' # HELLO \n",
    "words = ['HELL', 'HELLO', 'WORLD', 'OWORLD', 'TEST', 'L', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 2 # HELLO, HELL O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-spider",
   "metadata": {},
   "source": [
    "### short sample message - multiple options with permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence = '......-...-..---' # HELLO with confusion EH/HE\n",
    "words = ['HELL', 'HELLO', 'WORLD', 'OWORLD', 'TEST', 'HE', 'EH', 'L', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 4 # HELLO, HELL O, HE L L O, EH L L O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-reset",
   "metadata": {},
   "source": [
    "### sample message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence = '......-...-..---.-----.-..-..-..' # HELLOWORLD\n",
    "words = ['HELL', 'HELLO', 'WORLD', 'OWORLD', 'TEST'] \n",
    "\n",
    "start = time.perf_counter()\n",
    "res = count_runner(morse_sentence, words)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 2 # HELLO WORLD, HELL OWORLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-studio",
   "metadata": {},
   "source": [
    "### other sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence = '--.-------..' # HELLOWORLD\n",
    "words = ['GOD', 'GOOD', 'MORNING', 'G', 'HELLO'] \n",
    "\n",
    "start = time.perf_counter()\n",
    "res = count_runner(morse_sentence, words)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1 # HELLO WORLD, HELL OWORLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-circumstances",
   "metadata": {},
   "source": [
    "count avec startwith \n",
    "unitaire  5.9784999997702926e-05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-anthony",
   "metadata": {},
   "source": [
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-least",
   "metadata": {},
   "source": [
    "# long string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-finish",
   "metadata": {},
   "source": [
    "### long string generation fixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_random_morse_sentence(length, signs=None, seed=1234, chunk_size=None):\n",
    "    random.seed(seed)\n",
    "    sentence = []\n",
    "    stats = {}\n",
    "    tokens = []\n",
    "    current_token = []\n",
    "    if not chunk_size: chunk_size = random.randint(0, 4) + random.randint(0, 16)\n",
    "\n",
    "    if not signs: signs = list(alphabet_map.keys())\n",
    "    max_sign = len(signs) -1\n",
    "    for s in signs:\n",
    "        stats[s] = 0\n",
    "    for i in range(length):\n",
    "        letter = signs[random.randint(0, max_sign)]\n",
    "        sentence.append(alphabet_map[letter])\n",
    "        stats[letter] += 1\n",
    "        current_token.append(letter)\n",
    "        if len(current_token) >= chunk_size:\n",
    "            tokens.append(''.join(current_token))\n",
    "            current_token = []\n",
    "    \n",
    "    if current_token:\n",
    "        tokens.append(''.join(current_token))\n",
    "         \n",
    "    unique_tokens = list(set(tokens))\n",
    "    \n",
    "    return ''.join(sentence), stats, unique_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_map = morse.get_encoded_letters_map()\n",
    "\n",
    "generated_morse_sentence, stats, tokens = generate_random_morse_sentence(1, signs='E', chunk_size=5)\n",
    "assert len(generated_morse_sentence) == 1\n",
    "assert stats['E'] == 1\n",
    "\n",
    "generated_morse_sentence, stats, tokens = generate_random_morse_sentence(2, signs='ET', chunk_size=5)\n",
    "assert len(generated_morse_sentence) == 2\n",
    "assert stats['E'] == 1\n",
    "assert stats['T'] == 1\n",
    "\n",
    "generated_morse_sentence, stats, tokens = generate_random_morse_sentence(2, chunk_size=5)\n",
    "assert len(generated_morse_sentence) == 7\n",
    "assert stats['O'] == 1\n",
    "assert stats['Y'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_morse_sentence, stats, tokens = generate_random_morse_sentence(10, signs='ET', chunk_size=5)\n",
    "print(tokens)\n",
    "assert len(tokens) == 2\n",
    "assert len(tokens[0]) == 5\n",
    "assert len(tokens[1]) == 5\n",
    "assert tokens[0] == 'TEEEE'\n",
    "assert tokens[1] == 'EETEE'\n",
    "\n",
    "generated_morse_sentence, stats, tokens = generate_random_morse_sentence(10, signs='E', chunk_size=5)\n",
    "print(tokens)\n",
    "assert len(tokens) == 1\n",
    "assert len(tokens[0]) == 5\n",
    "assert tokens[0] == 'EEEEE'\n",
    "\n",
    "generated_morse_sentence, stats, tokens = generate_random_morse_sentence(8, signs='E', chunk_size=5)\n",
    "print(tokens)\n",
    "assert len(tokens) == 2\n",
    "assert len(tokens[0]) == 3\n",
    "assert len(tokens[1]) == 5\n",
    "assert tokens[0] == 'EEE'\n",
    "assert tokens[1] == 'EEEEE'\n",
    "\n",
    "generated_morse_sentence, stats, tokens = generate_random_morse_sentence(8, chunk_size=2)\n",
    "print(tokens)\n",
    "assert len(tokens) == 4\n",
    "assert len(tokens[0]) == 2\n",
    "assert tokens[0] == 'YO'\n",
    "\n",
    "generated_morse_sentence, stats, tokens = generate_random_morse_sentence(40)\n",
    "print(tokens)\n",
    "assert len(tokens) == 7\n",
    "assert tokens[0] == 'ACZSBV'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-willow",
   "metadata": {},
   "source": [
    "### long string - 1-char word - 1 option - stackoverflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-christian",
   "metadata": {},
   "source": [
    "assume count for 1 word is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence, stats, tokens = generate_random_morse_sentence(4000, signs='E')\n",
    "print(f'stats {stats}')\n",
    "print(f'length {len(morse_sentence)}')\n",
    "words = ['E'] \n",
    "\n",
    "start = time.perf_counter() \n",
    "res = count_runner(morse_sentence, words)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-amazon",
   "metadata": {},
   "source": [
    "### long string - 2 1-char words - multiple options - stackoverflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence, stats, tokens = generate_random_morse_sentence(4000, signs='ET')\n",
    "print(f'stats {stats}')\n",
    "print(f'length {len(morse_sentence)}')\n",
    "words = ['E', 'T'] \n",
    "\n",
    "start = time.perf_counter()\n",
    "res = count_runner(morse_sentence, words)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-hartford",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-hacker",
   "metadata": {},
   "source": [
    "### long string - few words - multiple options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-fabric",
   "metadata": {},
   "source": [
    "issue = a large number of words ':' -> execeed recursion limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence, stats, tokens = generate_random_morse_sentence(40, signs='E', chunk_size=5)\n",
    "print(f'stats {stats}')\n",
    "print(f'length {len(morse_sentence)}')\n",
    "words = tokens\n",
    "print(f'nb words {len(words)}')\n",
    "\n",
    "start = time.perf_counter()\n",
    "res = count_runner(morse_sentence, words)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-purse",
   "metadata": {},
   "source": [
    "### long string - few words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence, stats, tokens = generate_random_morse_sentence(4000, signs='ET')\n",
    "print(f'stats {stats}')\n",
    "print(f'length {len(morse_sentence)}')\n",
    "words = tokens\n",
    "print(f'nb words {len(words)}')\n",
    "\n",
    "start = time.perf_counter()\n",
    "res = count_runner(morse_sentence, words)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-hungarian",
   "metadata": {},
   "source": [
    "### long string - more words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence, stats, tokens = generate_random_morse_sentence(4000)\n",
    "print(f'stats {stats}')\n",
    "print(f'length {len(morse_sentence)}')\n",
    "words = tokens\n",
    "print(f'nb words {len(words)}')\n",
    "\n",
    "start = time.perf_counter()\n",
    "res = count_runner(morse_sentence, words)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-column",
   "metadata": {},
   "source": [
    "### long sentence - permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence, stats, tokens = generate_random_morse_sentence(4000, signs='EISH')\n",
    "print(f'stats {stats}')\n",
    "print(f'length {len(morse_sentence)}')\n",
    "words = tokens\n",
    "print(f'nb words {len(words)}')\n",
    "\n",
    "start = time.perf_counter()\n",
    "res = count_runner(morse_sentence, words)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-support",
   "metadata": {},
   "source": [
    "## long sentence - with repeating pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-whale",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence = '.-.-.-.-.-.-.-.-' # ETETETETETETETET\n",
    "words = ['E', 'T'] \n",
    "\n",
    "start = time.perf_counter()\n",
    "res = count_runner(morse_sentence, words)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1 # HELLO WORLD, HELL OWORLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-opportunity",
   "metadata": {},
   "source": [
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-trunk",
   "metadata": {},
   "source": [
    "# many words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_words(nb, max_length=20, signs=None, seed=1234):\n",
    "    random.seed(seed)\n",
    "    words = []\n",
    "    \n",
    "    for i in range(nb):\n",
    "        current_token = []\n",
    "        size = random.randint(0, 4) + random.randint(0, max_length)\n",
    "\n",
    "        #if not signs: signs = list(alphabet_map.keys())\n",
    "        #max_sign = len(signs) -1\n",
    "        #for s in signs:\n",
    "        #    stats[s] = 0\n",
    "        for i in range(size):\n",
    "            letter = random.randint(0, 25)\n",
    "            current_token.append('ABCDEFGHIJKLMNOPQRSTUVWXYZ'[letter])\n",
    "            #stats[letter] += 1\n",
    "        words.append(''.join(current_token))\n",
    "         \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_map = morse.get_encoded_letters_map()\n",
    "nb = 10000\n",
    "\n",
    "start = time.perf_counter()\n",
    "words = generate_words(nb, seed=1234)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "assert len(words) == nb\n",
    "print(words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-rating",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "lengths = {w:len(w) for w in words}\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-favorite",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "for w in words:\n",
    "    n = lengths[w]\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-acrobat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
