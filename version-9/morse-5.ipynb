{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "considered-medium",
   "metadata": {},
   "source": [
    "# morse alphabet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accessory-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-metro",
   "metadata": {},
   "source": [
    "### Morse Alphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-treasury",
   "metadata": {},
   "source": [
    "A  .- \t B  -... \t C  -.-. \t D  -..\n",
    "E  . \t F  ..-. \t G  --. \t H  ....\n",
    "I  .. \t J  .--- \t K  -.- \t L  .-..\n",
    "M  -- \t N  -. \t O  --- \t P  .--.\n",
    "Q  --.- \t R  .-. \t S  ... \t T  -\n",
    "U  ..- \t V  ...- \t W  .-- \t X  -..-\n",
    "Y  -.-- \t Z  --.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "educational-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphabet import MorseAlphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incorporate-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse = MorseAlphabet()\n",
    "assert morse.get_encoded_letters_map()['D'] == '-..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "registered-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordencoder import WordEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "local-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = WordEncoder()\n",
    "encoder.add_word_list(['HTE', 'EE'])\n",
    "assert len(encoder.get_list()) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-bishop",
   "metadata": {},
   "source": [
    "#### version 5 6 \n",
    "- basic reducer with remaining\n",
    "- replace list manipulations with node -> still bumpinto the reccursion  limitation\n",
    "- replace reccursion with command pattern -> still too long \n",
    "- options object - keep track of solved positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intermediate-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from context import Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sudden-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "from node import Node, NodeState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "respected-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = '..-.--.'\n",
    "node_0 = Node('', 0, len(sentence1), state=NodeState.ROOT)\n",
    "node_1 = Node('..', 2, len('-.--.'), parent=node_0)\n",
    "node_2 = Node('-', 3, len('.--.'), parent=node_1)\n",
    "node_3 = Node('.--', 4, len('.'), parent=node_2)\n",
    "node_4 = Node('.', 7, len(''), parent=node_3)\n",
    "#print(node_4.get_sequence())\n",
    "#origin = node_4.get_sequence_start()\n",
    "#assert origin.get_sequence() == ''\n",
    "#assert origin.get_sequence() == NodeState.ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sexual-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tasklist import TaskList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "subject-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = '..-.--.'\n",
    "node_0 = Node('', 0, len(sentence1), state=NodeState.ROOT)\n",
    "tasklist = TaskList(node_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fallen-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dramatic-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDecoder():\n",
    "    def __init__(self, context, verbose=False):\n",
    "        self.context = context\n",
    "        self.sentence = None\n",
    "        self.nb_sentence_signs = 0\n",
    "        self.valid_words_map = context.get_encoder().get_dict()\n",
    "        self.options = None\n",
    "        self.verbose = verbose\n",
    "        self.task_list = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "italic-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to SentenceDecoder\n",
    "def screen_words(self, encoded_words_map):\n",
    "    valid_encoded_words_maps = { k:v for k,v in encoded_words_map.items() if self.sentence.find(k)>=0}\n",
    "    print(f'nb possible words {len(valid_encoded_words_maps.keys())}')\n",
    "    return valid_encoded_words_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "forty-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to SentenceDecoder\n",
    "def log2(self, message):\n",
    "    print(message, file=sys.stderr, flush=True)\n",
    "\n",
    "def debug(self, category, level, formated, duplicates=0):\n",
    "    if self.verbose:\n",
    "        message = f'{category}.{level} {formated} *{duplicates}'\n",
    "        print(message, file=sys.stderr, flush=True)\n",
    "\n",
    "def get_formated(self, node, word=None):\n",
    "    text = ''\n",
    "    if self.verbose:\n",
    "        left = node.get_sequence() if node else ''\n",
    "        pos = node.pos\n",
    "        if word:\n",
    "            right = self.sentence[node.pos+len(word):]  # node.remaining\n",
    "            text = f'[{left} <= @{pos}({word}) => {right}]'\n",
    "        else:\n",
    "            right = self.sentence[node.next_pos:]  # node.remaining\n",
    "            if right:\n",
    "                text = f'[{left} <=> {right}]'\n",
    "            else:\n",
    "                text = f'[{left}]'\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "greenhouse-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to SentenceDecoder\n",
    "def decode_1(self, sentence):\n",
    "    # dumb cases\n",
    "    if len(sentence) == 0: \n",
    "        self.log2('empty sentence')\n",
    "        return 0      \n",
    "\n",
    "    self.sentence = sentence\n",
    "\n",
    "    self.valid_words_map = self.screen_words(self.valid_words_map)\n",
    "    if len(self.valid_words_map.keys()) == 0: \n",
    "        self.log2('empty words')\n",
    "        return 0\n",
    "    #print(f'valid_words_map {self.valid_words_map}')\n",
    "\n",
    "    count_loops = 0\n",
    "    #self.options = Options(len(sentence))\n",
    "    start_node = Node('', 0, self.sentence, state=NodeState.ROOT, level=0) \n",
    "    commands = [start_node]\n",
    "    nb_options = 0\n",
    "    while commands:\n",
    "        count_loops += 1\n",
    "        # sort by pos\n",
    "        #commands.sort(key=lambda c: c.pos, reverse=True)\n",
    "        self.log2(f'loop:{count_loops}, nb_commands:{len(commands)}')\n",
    "        commands, nb_options = self.decode_loop(commands, nb_options)\n",
    "\n",
    "    return nb_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "overall-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to SentenceDecoder\n",
    "def decode_loop_1(self, commands, last_nb_options):\n",
    "    nb_options = last_nb_options\n",
    "    new_commands = []\n",
    "    for last_node in commands:\n",
    "        level = last_node.level + 1\n",
    "        remaining = last_node.remaining\n",
    "        current_pos = last_node.next_pos\n",
    "\n",
    "        if last_node.is_done: \n",
    "            nb_options_for_sequence = last_node.get_nb_options()  \n",
    "            self.debug('done', level, self.get_formated(last_node), nb_options_for_sequence)\n",
    "            nb_options += nb_options_for_sequence\n",
    "        else:\n",
    "            #N = 20\n",
    "            #for length in range(N):\n",
    "            #    word = remaining[0:length]\n",
    "            #    if word in self.valid_words_map:\n",
    "            #        duplicates = self.valid_words_map[word]\n",
    "            for word, duplicates in self.valid_words_map.items():\n",
    "                i = len(word)\n",
    "                #if len(remaining) >= i and remaining[0:i]:\n",
    "                if len(remaining) >= i and remaining.startswith(word):\n",
    "                    new_remaining = str(remaining[i:])\n",
    "                    new_node = Node(word, current_pos, new_remaining, duplicates=duplicates, parent=last_node)\n",
    "                    new_commands.append(new_node)\n",
    "\n",
    "    return new_commands, nb_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "functional-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to SentenceDecoder\n",
    "def decode(self, sentence):\n",
    "    # dumb cases\n",
    "    if len(sentence) == 0: \n",
    "        self.log2('empty sentence')\n",
    "        return 0      \n",
    "\n",
    "    self.sentence = sentence\n",
    "    self.nb_sentence_signs = len(self.sentence)\n",
    "\n",
    "    self.valid_words_map = self.screen_words(self.valid_words_map)\n",
    "    if len(self.valid_words_map.keys()) == 0: \n",
    "        self.log2('empty words')\n",
    "        return 0\n",
    "    #print(f'valid_words_map {self.valid_words_map}')\n",
    "\n",
    "    count_loops = 0\n",
    "    chunk_size = 10\n",
    "    start_node = Node('', 0, self.nb_sentence_signs, state=NodeState.ROOT, level=0) \n",
    "    self.task_list = TaskList(start_node)\n",
    "    nb_options = 0\n",
    "    nodes = self.task_list.next(size=chunk_size)\n",
    "    while nodes:\n",
    "        count_loops += 1\n",
    "        # self.log2(f'loop:{count_loops} nodes:{nodes}')\n",
    "        nb_options = self.decode_loop(nodes, nb_options)\n",
    "        nodes = self.task_list.next(size=chunk_size)\n",
    "\n",
    "    self.log2(f'loop:{count_loops}')\n",
    "    return nb_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "actual-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to SentenceDecoder\n",
    "def decode_loop_2(self, nodes, last_nb_options):\n",
    "    nb_options = last_nb_options\n",
    "    for last_node in nodes:\n",
    "        level = last_node.level + 1\n",
    "        remaining = last_node.remaining\n",
    "        current_pos = last_node.next_pos\n",
    "\n",
    "        if last_node.is_done: \n",
    "            nb_options_for_sequence = last_node.get_nb_options()  \n",
    "            self.debug('done', level, self.get_formated(last_node), nb_options_for_sequence)\n",
    "            nb_options += nb_options_for_sequence\n",
    "        else:\n",
    "            self.debug('loop', level, self.get_formated(last_node))\n",
    "            for word, duplicates in self.valid_words_map.items():\n",
    "                i = len(word)\n",
    "                if len(remaining) >= i and remaining[0:i]:\n",
    "                #if len(remaining) >= len(word) and remaining.startswith(word):\n",
    "                    self.debug('word', level, self.get_formated(last_node, word), duplicates)\n",
    "                    i = len(word)\n",
    "                    new_remaining = str(remaining[i:])\n",
    "                    new_node = Node(word, current_pos, new_remaining, duplicates=duplicates, parent=last_node)\n",
    "                    self.debug('cont', level, self.get_formated(new_node, word), duplicates)\n",
    "                    self.task_list.add(new_node)\n",
    "\n",
    "    return nb_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "industrial-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to SentenceDecoder\n",
    "\n",
    "def decode_loop_done(self, last_node):\n",
    "    level = last_node.level + 1\n",
    "    nb_options_for_sequence = last_node.get_nb_options()  \n",
    "    self.debug('done', level, self.get_formated(last_node), nb_options_for_sequence)\n",
    "    return nb_options_for_sequence\n",
    "\n",
    "def decode_loop_lookup(self, last_node):\n",
    "    level = last_node.level + 1\n",
    "    current_pos = last_node.next_pos\n",
    "    #self.debug('loop', level, self.get_formated(last_node))\n",
    "    for word, duplicates in self.valid_words_map.items():\n",
    "        nb_word_signs = len(word)\n",
    "        #self.debug('word', level, self.get_formated(last_node, word), duplicates)\n",
    "        if last_node.nb_remaining >= nb_word_signs:\n",
    "            self.decode_loop_check_word(last_node, word, nb_word_signs, current_pos, duplicates)\n",
    "\n",
    "# !!!\n",
    "def decode_loop_check_word(self, last_node, word, nb_word_signs, current_pos, duplicates):\n",
    "    #if self.sentence[current_pos:current_pos+nb_word_signs] == word:\n",
    "    if self.decode_loop_slice(current_pos, nb_word_signs) == word:\n",
    "        self.decode_loop_new_node(last_node, word, nb_word_signs, current_pos, duplicates)\n",
    "\n",
    "def decode_loop_slice(self, current_pos, nb_word_signs):\n",
    "    return self.sentence[current_pos:current_pos+nb_word_signs]\n",
    "\n",
    "def decode_loop_new_node(self, last_node, word, nb_word_signs, current_pos, duplicates):\n",
    "    nb_remaining_signs = last_node.nb_remaining - nb_word_signs\n",
    "    new_node = Node(word, current_pos, nb_remaining_signs, duplicates=duplicates, parent=last_node)\n",
    "    #self.debug('cont', level, self.get_formated(new_node), duplicates)\n",
    "    self.task_list.add(new_node)\n",
    "\n",
    "\n",
    "def decode_loop(self, nodes, last_nb_options):\n",
    "    nb_options = last_nb_options\n",
    "    for last_node in nodes:\n",
    "        if last_node.is_done: \n",
    "             nb_options += self.decode_loop_done(last_node)\n",
    "        else:\n",
    "            self.decode_loop_lookup(last_node)\n",
    "\n",
    "    return nb_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "closing-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_runner(target_sentence, words, verbose=False):\n",
    "    print(f'nb words {len(words)}')\n",
    "             \n",
    "    # sort words by length\n",
    "    #words.sort(key=len, reverse=True)\n",
    "    \n",
    "    word_encoder = WordEncoder()\n",
    "    word_encoder.add_word_list(words)\n",
    "    if verbose:\n",
    "        print(f'encoded words {word_encoder.get_dict()}')\n",
    "    print(f'nb encoded words {len(word_encoder.get_dict())}')\n",
    "\n",
    "    context = Context(word_encoder=word_encoder)\n",
    "    decoder = SentenceDecoder(context, verbose)\n",
    "    res = decoder.decode(target_sentence)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "choice-seeker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-germany",
   "metadata": {},
   "source": [
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-advance",
   "metadata": {},
   "source": [
    "# unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-aluminum",
   "metadata": {},
   "source": [
    "### empty sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "unlikely-treat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "empty sentence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb words 3\n",
      "nb encoded words 3\n",
      "count: 0\n"
     ]
    }
   ],
   "source": [
    "morse_sentence = '' \n",
    "words = ['SE', 'T', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-processor",
   "metadata": {},
   "source": [
    "### empty words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "planned-bobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "empty words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb words 0\n",
      "nb encoded words 0\n",
      "nb possible words 0\n",
      "count: 0\n"
     ]
    }
   ],
   "source": [
    "morse_sentence = '-' # T \n",
    "words = [] \n",
    "\n",
    "res = count_runner(morse_sentence, words)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-crazy",
   "metadata": {},
   "source": [
    "### one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "known-robin",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop.1 [ <=> -] *0\n",
      "word.1 [ <= @0(-) => ] *1\n",
      "cont.1 [-] *1\n",
      "done.1 [-] *1\n",
      "loop:2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb words 1\n",
      "encoded words {'-': 1}\n",
      "nb encoded words 1\n",
      "nb possible words 1\n",
      "count: 1\n"
     ]
    }
   ],
   "source": [
    "morse_sentence = '-' # T \n",
    "words = ['T'] \n",
    "\n",
    "res = count_runner(morse_sentence, words, verbose=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "specified-peeing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop.1 [ <=> --] *0\n",
      "word.1 [ <= @0(-) => -] *1\n",
      "cont.1 [- <=> -] *1\n",
      "word.1 [ <= @0(--) => ] *1\n",
      "cont.1 [--] *1\n",
      "done.1 [--] *1\n",
      "loop.1 [- <=> -] *0\n",
      "word.1 [- <= @0(-) => -] *1\n",
      "cont.1 [-|-] *1\n",
      "word.1 [- <= @0(--) => ] *1\n",
      "done.1 [-|-] *1\n",
      "loop:4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb words 3\n",
      "encoded words {'-': 1, '-..-': 1, '--': 1}\n",
      "nb encoded words 3\n",
      "nb possible words 2\n",
      "count: 2\n"
     ]
    }
   ],
   "source": [
    "morse_sentence = '--' # T \n",
    "words = ['T', 'X', 'M'] \n",
    "\n",
    "res = count_runner(morse_sentence, words, verbose=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 2 # TT, M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-universal",
   "metadata": {},
   "source": [
    "### One letter - one option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "postal-primary",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop.1 [ <=> -] *0\n",
      "word.1 [ <= @0(-) => ] *1\n",
      "cont.1 [-] *1\n",
      "done.1 [-] *1\n",
      "loop:2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb words 3\n",
      "encoded words {'....': 1, '-': 1, '---': 1}\n",
      "nb encoded words 3\n",
      "nb possible words 1\n",
      "count: 1\n"
     ]
    }
   ],
   "source": [
    "morse_sentence = '-' # T\n",
    "words = ['SE', 'T', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words, verbose=True)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1 # T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-fiber",
   "metadata": {},
   "source": [
    "### very few words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "entitled-conversation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop.1 [ <=> -.-.] *0\n",
      "word.1 [ <= @0(-.) => -.] *1\n",
      "cont.1 [-. <=> -.] *1\n",
      "loop.1 [-. <=> -.] *0\n",
      "word.1 [-. <= @0(-.) => -.] *1\n",
      "cont.1 [-.|-.] *1\n",
      "done.1 [-.|-.] *1\n",
      "loop:3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb words 1\n",
      "encoded words {'-.': 1}\n",
      "nb encoded words 1\n",
      "nb possible words 1\n",
      "count: 1\n"
     ]
    }
   ],
   "source": [
    "morse_sentence = '-.-.' # TETE\n",
    "words = ['TE'] \n",
    "\n",
    "res = count_runner(morse_sentence, words, verbose=True)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1 # TE TE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "tribal-worse",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop.1 [ <=> -.-.] *0\n",
      "word.1 [ <= @0(-) => .-.] *1\n",
      "cont.1 [- <=> .-.] *1\n",
      "word.1 [ <= @0(.) => .-.] *1\n",
      "loop.1 [- <=> .-.] *0\n",
      "word.1 [- <= @0(-) => .-.] *1\n",
      "word.1 [- <= @0(.) => .-.] *1\n",
      "cont.1 [-|. <=> -.] *1\n",
      "loop.1 [-|. <=> -.] *0\n",
      "word.1 [-|. <= @1(-) => -.] *1\n",
      "cont.1 [-|.|- <=> .] *1\n",
      "word.1 [-|. <= @1(.) => -.] *1\n",
      "loop.1 [-|.|- <=> .] *0\n",
      "word.1 [-|.|- <= @2(-) => .] *1\n",
      "word.1 [-|.|- <= @2(.) => .] *1\n",
      "cont.1 [-|.|-|.] *1\n",
      "done.1 [-|.|-|.] *1\n",
      "loop:5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb words 2\n",
      "encoded words {'-': 1, '.': 1}\n",
      "nb encoded words 2\n",
      "nb possible words 2\n",
      "count: 1\n"
     ]
    }
   ],
   "source": [
    "morse_sentence = '-.-.' # TETE\n",
    "words = ['T','E'] \n",
    "\n",
    "res = count_runner(morse_sentence, words, verbose=True)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1 # TE TE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-samoa",
   "metadata": {},
   "source": [
    "### short message - multiple options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "exclusive-occasions",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop.1 [ <=> ....] *0\n",
      "word.1 [ <= @0(....) => ] *4\n",
      "cont.1 [....] *4\n",
      "done.1 [....] *4\n",
      "loop:2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb words 6\n",
      "encoded words {'....': 4, '.-..': 1, '---': 1}\n",
      "nb encoded words 3\n",
      "nb possible words 1\n",
      "count: 4\n"
     ]
    }
   ],
   "source": [
    "morse_sentence = '....' # E . I .. S ... H ....\n",
    "words = ['EIE', 'SE', 'ES', 'H', 'L', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words, verbose=True)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 4 # EIE, ES, H, SE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-explosion",
   "metadata": {},
   "source": [
    "### no match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "innovative-accuracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "empty words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb words 3\n",
      "encoded words {'-..-': 1, '.-..': 1, '---': 1}\n",
      "nb encoded words 3\n",
      "nb possible words 0\n",
      "count: 0\n"
     ]
    }
   ],
   "source": [
    "morse_sentence = '....' # E . I .. S ... H ....\n",
    "words = ['X', 'L', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words, verbose=True)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 0 # no match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-synthesis",
   "metadata": {},
   "source": [
    "### short message - multiple options with permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "nasty-fighter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop.1 [ <=> .....] *0\n",
      "word.1 [ <= @0(.....) => ] *2\n",
      "cont.1 [.....] *2\n",
      "done.1 [.....] *2\n",
      "loop:2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb words 4\n",
      "encoded words {'......-..': 1, '.....': 2, '---': 1}\n",
      "nb encoded words 3\n",
      "nb possible words 1\n",
      "count: 2\n"
     ]
    }
   ],
   "source": [
    "morse_sentence = '.....' # confusion EH/HE\n",
    "words = ['HEL', 'HE', 'EH', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words, verbose=True)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 2 # HE, EH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-cleanup",
   "metadata": {},
   "source": [
    "### short message - one option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "major-immunology",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop.1 [ <=> ......-..] *0\n",
      "word.1 [ <= @0(......-..) => ] *1\n",
      "cont.1 [......-..] *1\n",
      "done.1 [......-..] *1\n",
      "loop:2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb words 2\n",
      "encoded words {'......-..': 1, '---': 1}\n",
      "nb encoded words 2\n",
      "nb possible words 1\n",
      "count: 1\n"
     ]
    }
   ],
   "source": [
    "morse_sentence = '......-..' # HEL single option\n",
    "words = ['HEL', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words, verbose=True)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1 # HEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-scratch",
   "metadata": {},
   "source": [
    "### short message - multiple options with partial match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "daily-intervention",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop.1 [ <=> ......-..] *0\n",
      "word.1 [ <= @0(......-..) => ] *1\n",
      "cont.1 [......-..] *1\n",
      "word.1 [ <= @0(.....) => .-..] *1\n",
      "cont.1 [..... <=> .-..] *1\n",
      "word.1 [ <= @0(.-..) => ..-..] *1\n",
      "done.1 [......-..] *1\n",
      "loop.1 [..... <=> .-..] *0\n",
      "word.1 [..... <= @0(......-..) => ] *1\n",
      "word.1 [..... <= @0(.....) => .-..] *1\n",
      "word.1 [..... <= @0(.-..) => ..-..] *1\n",
      "cont.1 [.....|.-..] *1\n",
      "done.1 [.....|.-..] *1\n",
      "loop:4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb words 4\n",
      "encoded words {'......-..': 1, '.....': 1, '.-..': 1, '---': 1}\n",
      "nb encoded words 4\n",
      "nb possible words 3\n",
      "count: 2\n"
     ]
    }
   ],
   "source": [
    "morse_sentence = '......-..' # HEL or HE L\n",
    "words = ['HEL', 'HE', 'L', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words, verbose=True)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 2 # HEL, HE L  -- fix stops when HE L is found and never reach HEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-disabled",
   "metadata": {},
   "source": [
    "### short message - multiple options with partial match and permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "healthy-groove",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop.1 [ <=> ......-..] *0\n",
      "word.1 [ <= @0(......-..) => ] *1\n",
      "cont.1 [......-..] *1\n",
      "word.1 [ <= @0(.....) => .-..] *2\n",
      "cont.1 [..... <=> .-..] *2\n",
      "word.1 [ <= @0(.-..) => ..-..] *1\n",
      "done.1 [......-..] *1\n",
      "loop.1 [..... <=> .-..] *0\n",
      "word.1 [..... <= @0(......-..) => ] *1\n",
      "word.1 [..... <= @0(.....) => .-..] *2\n",
      "word.1 [..... <= @0(.-..) => ..-..] *1\n",
      "cont.1 [.....|.-..] *1\n",
      "done.1 [.....|.-..] *2\n",
      "loop:4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb words 5\n",
      "encoded words {'......-..': 1, '.....': 2, '.-..': 1, '---': 1}\n",
      "nb encoded words 4\n",
      "nb possible words 3\n",
      "count: 3\n"
     ]
    }
   ],
   "source": [
    "morse_sentence = '......-..' # HEL with confusion EH/HE\n",
    "words = ['HEL', 'HE', 'EH', 'L', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words, verbose=True)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 3 # HEL, HE L, EH L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-chocolate",
   "metadata": {},
   "source": [
    "### short sample message - multiple options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "extra-sharing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop.1 [ <=> ......-...-..---] *0\n",
      "word.1 [ <= @0(......-...-..) => ---] *1\n",
      "cont.1 [......-...-.. <=> ---] *1\n",
      "word.1 [ <= @0(......-...-..---) => ] *1\n",
      "cont.1 [......-...-..---] *1\n",
      "word.1 [ <= @0(.-..) => ..-...-..---] *1\n",
      "word.1 [ <= @0(---) => ...-...-..---] *1\n",
      "done.1 [......-...-..---] *1\n",
      "loop.1 [......-...-.. <=> ---] *0\n",
      "word.1 [......-...-.. <= @0(......-...-..) => ---] *1\n",
      "word.1 [......-...-.. <= @0(......-...-..---) => ] *1\n",
      "word.1 [......-...-.. <= @0(.-..) => ..-...-..---] *1\n",
      "word.1 [......-...-.. <= @0(---) => ...-...-..---] *1\n",
      "cont.1 [......-...-..|---] *1\n",
      "done.1 [......-...-..|---] *1\n",
      "loop:4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb words 7\n",
      "encoded words {'......-...-..': 1, '......-...-..---': 1, '.-----.-..-..-..': 1, '---.-----.-..-..-..': 1, '-....-': 1, '.-..': 1, '---': 1}\n",
      "nb encoded words 7\n",
      "nb possible words 4\n",
      "count: 2\n"
     ]
    }
   ],
   "source": [
    "morse_sentence = '......-...-..---' # HELLO \n",
    "words = ['HELL', 'HELLO', 'WORLD', 'OWORLD', 'TEST', 'L', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words, verbose=True)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 2 # HELLO, HELL O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-toilet",
   "metadata": {},
   "source": [
    "### short sample message - multiple options with permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sunset-japan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop.1 [ <=> ......-...-..---] *0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb words 9\n",
      "encoded words {'......-...-..': 1, '......-...-..---': 1, '.-----.-..-..-..': 1, '---.-----.-..-..-..': 1, '-....-': 1, '.....': 2, '.-..': 1, '---': 1}\n",
      "nb encoded words 8\n",
      "nb possible words 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "word.1 [ <= @0(......-...-..) => ---] *1\n",
      "cont.1 [......-...-.. <=> ---] *1\n",
      "word.1 [ <= @0(......-...-..---) => ] *1\n",
      "cont.1 [......-...-..---] *1\n",
      "word.1 [ <= @0(.....) => .-...-..---] *2\n",
      "cont.1 [..... <=> .-...-..---] *2\n",
      "word.1 [ <= @0(.-..) => ..-...-..---] *1\n",
      "word.1 [ <= @0(---) => ...-...-..---] *1\n",
      "done.1 [......-...-..---] *1\n",
      "loop.1 [......-...-.. <=> ---] *0\n",
      "word.1 [......-...-.. <= @0(......-...-..) => ---] *1\n",
      "word.1 [......-...-.. <= @0(......-...-..---) => ] *1\n",
      "word.1 [......-...-.. <= @0(.....) => .-...-..---] *2\n",
      "word.1 [......-...-.. <= @0(.-..) => ..-...-..---] *1\n",
      "word.1 [......-...-.. <= @0(---) => ...-...-..---] *1\n",
      "cont.1 [......-...-..|---] *1\n",
      "done.1 [......-...-..|---] *1\n",
      "loop.1 [..... <=> .-...-..---] *0\n",
      "word.1 [..... <= @0(......-...-..) => ---] *1\n",
      "word.1 [..... <= @0(......-...-..---) => ] *1\n",
      "word.1 [..... <= @0(.....) => .-...-..---] *2\n",
      "word.1 [..... <= @0(.-..) => ..-...-..---] *1\n",
      "cont.1 [.....|.-.. <=> .-..---] *1\n",
      "word.1 [..... <= @0(---) => ...-...-..---] *1\n",
      "loop.1 [.....|.-.. <=> .-..---] *0\n",
      "word.1 [.....|.-.. <= @5(......-...-..) => ] *1\n",
      "word.1 [.....|.-.. <= @5(......-...-..---) => ] *1\n",
      "word.1 [.....|.-.. <= @5(.....) => -..---] *2\n",
      "word.1 [.....|.-.. <= @5(.-..) => .-..---] *1\n",
      "cont.1 [.....|.-..|.-.. <=> ---] *1\n",
      "word.1 [.....|.-.. <= @5(---) => ..-..---] *1\n",
      "loop.1 [.....|.-..|.-.. <=> ---] *0\n",
      "word.1 [.....|.-..|.-.. <= @9(......-...-..) => ] *1\n",
      "word.1 [.....|.-..|.-.. <= @9(......-...-..---) => ] *1\n",
      "word.1 [.....|.-..|.-.. <= @9(.....) => --] *2\n",
      "word.1 [.....|.-..|.-.. <= @9(.-..) => ---] *1\n",
      "word.1 [.....|.-..|.-.. <= @9(---) => .---] *1\n",
      "cont.1 [.....|.-..|.-..|---] *1\n",
      "done.1 [.....|.-..|.-..|---] *2\n",
      "loop:8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 4\n"
     ]
    }
   ],
   "source": [
    "morse_sentence = '......-...-..---' # HELLO with confusion EH/HE\n",
    "words = ['HELL', 'HELLO', 'WORLD', 'OWORLD', 'TEST', 'HE', 'EH', 'L', 'O'] \n",
    "\n",
    "res = count_runner(morse_sentence, words, verbose=True)\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 4 # HELLO, HELL O, HE L L O, EH L L O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-logic",
   "metadata": {},
   "source": [
    "### sample message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "specified-fabric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb words 5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop.1 [ <=> ......-...-..---.-----.-..-..-..] *0\n",
      "word.1 [ <= @0(......-...-..) => ---.-----.-..-..-..] *1\n",
      "cont.1 [......-...-.. <=> ---.-----.-..-..-..] *1\n",
      "word.1 [ <= @0(......-...-..---) => .-----.-..-..-..] *1\n",
      "cont.1 [......-...-..--- <=> .-----.-..-..-..] *1\n",
      "word.1 [ <= @0(.-----.-..-..-..) => .-----.-..-..-..] *1\n",
      "word.1 [ <= @0(---.-----.-..-..-..) => ---.-..-..-..] *1\n",
      "loop.1 [......-...-..--- <=> .-----.-..-..-..] *0\n",
      "word.1 [......-...-..--- <= @0(......-...-..) => ---.-----.-..-..-..] *1\n",
      "word.1 [......-...-..--- <= @0(......-...-..---) => .-----.-..-..-..] *1\n",
      "word.1 [......-...-..--- <= @0(.-----.-..-..-..) => .-----.-..-..-..] *1\n",
      "cont.1 [......-...-..---|.-----.-..-..-..] *1\n",
      "word.1 [......-...-..--- <= @0(---.-----.-..-..-..) => ---.-..-..-..] *1\n",
      "done.1 [......-...-..---|.-----.-..-..-..] *1\n",
      "loop.1 [......-...-.. <=> ---.-----.-..-..-..] *0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "encoded words {'......-...-..': 1, '......-...-..---': 1, '.-----.-..-..-..': 1, '---.-----.-..-..-..': 1, '-....-': 1}\n",
      "nb encoded words 5\n",
      "nb possible words 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "word.1 [......-...-.. <= @0(......-...-..) => ---.-----.-..-..-..] *1\n",
      "word.1 [......-...-.. <= @0(......-...-..---) => .-----.-..-..-..] *1\n",
      "word.1 [......-...-.. <= @0(.-----.-..-..-..) => .-----.-..-..-..] *1\n",
      "word.1 [......-...-.. <= @0(---.-----.-..-..-..) => ---.-..-..-..] *1\n",
      "cont.1 [......-...-..|---.-----.-..-..-..] *1\n",
      "done.1 [......-...-..|---.-----.-..-..-..] *1\n",
      "loop:5\n",
      "duration 0.017806156999999878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 2\n"
     ]
    }
   ],
   "source": [
    "morse_sentence = '......-...-..---.-----.-..-..-..' # HELLOWORLD\n",
    "words = ['HELL', 'HELLO', 'WORLD', 'OWORLD', 'TEST'] \n",
    "\n",
    "start = time.perf_counter()\n",
    "res = count_runner(morse_sentence, words, verbose=True)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 2 # HELLO WORLD, HELL OWORLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-jimmy",
   "metadata": {},
   "source": [
    "### other sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "forbidden-redhead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop.1 [ <=> --.-------..] *0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb words 5\n",
      "encoded words {'--.----..': 1, '--.-------..': 1, '-----.-.-...-.--.': 1, '--.': 1, '......-...-..---': 1}\n",
      "nb encoded words 5\n",
      "nb possible words 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "word.1 [ <= @0(--.-------..) => ] *1\n",
      "cont.1 [--.-------..] *1\n",
      "word.1 [ <= @0(--.) => -------..] *1\n",
      "cont.1 [--. <=> -------..] *1\n",
      "done.1 [--.-------..] *1\n",
      "loop.1 [--. <=> -------..] *0\n",
      "word.1 [--. <= @0(--.-------..) => ] *1\n",
      "word.1 [--. <= @0(--.) => -------..] *1\n",
      "loop:3\n",
      "duration 0.009379651999999794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 1\n"
     ]
    }
   ],
   "source": [
    "morse_sentence = '--.-------..' # HELLOWORLD\n",
    "words = ['GOD', 'GOOD', 'MORNING', 'G', 'HELLO'] \n",
    "# A .- B -... C -.-. D -.. E . F ..-. G --. H .... \n",
    "# I .. J .--- K -.- L .-.. M -- N -. O --- P .--. \n",
    "# Q --.- R .-. S ... T - U ..- V ...- W .-- X -..- Y -.-- Z --..\n",
    "start = time.perf_counter()\n",
    "res = count_runner(morse_sentence, words, verbose=True)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1 # GOOD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-ideal",
   "metadata": {},
   "source": [
    "count avec startwith \n",
    "unitaire  5.9784999997702926e-05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-president",
   "metadata": {},
   "source": [
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-canon",
   "metadata": {},
   "source": [
    "# long string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-conjunction",
   "metadata": {},
   "source": [
    "### long string generation fixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "derived-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_random_morse_sentence(length, signs=None, seed=1234, chunk_size=None):\n",
    "    random.seed(seed)\n",
    "    sentence = []\n",
    "    stats = {}\n",
    "    tokens = []\n",
    "    current_token = []\n",
    "    if not chunk_size: chunk_size = random.randint(0, 4) + random.randint(0, 16)\n",
    "\n",
    "    if not signs: signs = list(alphabet_map.keys())\n",
    "    max_sign = len(signs) -1\n",
    "    for s in signs:\n",
    "        stats[s] = 0\n",
    "    for i in range(length):\n",
    "        letter = signs[random.randint(0, max_sign)]\n",
    "        sentence.append(alphabet_map[letter])\n",
    "        stats[letter] += 1\n",
    "        current_token.append(letter)\n",
    "        if len(current_token) >= chunk_size:\n",
    "            tokens.append(''.join(current_token))\n",
    "            current_token = []\n",
    "    \n",
    "    if current_token:\n",
    "        tokens.append(''.join(current_token))\n",
    "         \n",
    "    unique_tokens = list(set(tokens))\n",
    "    \n",
    "    return ''.join(sentence), stats, unique_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "failing-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_map = morse.get_encoded_letters_map()\n",
    "\n",
    "generated_morse_sentence, stats, tokens = generate_random_morse_sentence(1, signs='E', chunk_size=5)\n",
    "assert len(generated_morse_sentence) == 1\n",
    "assert stats['E'] == 1\n",
    "\n",
    "generated_morse_sentence, stats, tokens = generate_random_morse_sentence(2, signs='ET', chunk_size=5)\n",
    "assert len(generated_morse_sentence) == 2\n",
    "assert stats['E'] == 1\n",
    "assert stats['T'] == 1\n",
    "\n",
    "generated_morse_sentence, stats, tokens = generate_random_morse_sentence(2, chunk_size=5)\n",
    "assert len(generated_morse_sentence) == 7\n",
    "assert stats['O'] == 1\n",
    "assert stats['Y'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "pharmaceutical-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    generated_morse_sentence, stats, tokens = generate_random_morse_sentence(10, signs='ET', chunk_size=5)\n",
    "    print(tokens)\n",
    "    assert len(tokens) == 2\n",
    "    assert len(tokens[0]) == 5\n",
    "    assert len(tokens[1]) == 5\n",
    "    assert tokens[0] == 'TEEEE'\n",
    "    assert tokens[1] == 'EETEE'\n",
    "\n",
    "    generated_morse_sentence, stats, tokens = generate_random_morse_sentence(10, signs='E', chunk_size=5)\n",
    "    print(tokens)\n",
    "    assert len(tokens) == 1\n",
    "    assert len(tokens[0]) == 5\n",
    "    assert tokens[0] == 'EEEEE'\n",
    "\n",
    "    generated_morse_sentence, stats, tokens = generate_random_morse_sentence(8, signs='E', chunk_size=5)\n",
    "    print(tokens)\n",
    "    assert len(tokens) == 2\n",
    "    assert len(tokens[0]) == 3\n",
    "    assert len(tokens[1]) == 5\n",
    "    assert tokens[0] == 'EEE'\n",
    "    assert tokens[1] == 'EEEEE'\n",
    "\n",
    "    generated_morse_sentence, stats, tokens = generate_random_morse_sentence(8, chunk_size=2)\n",
    "    print(tokens)\n",
    "    assert len(tokens) == 4\n",
    "    assert len(tokens[0]) == 2\n",
    "    assert tokens[0] == 'YO'\n",
    "\n",
    "    generated_morse_sentence, stats, tokens = generate_random_morse_sentence(40)\n",
    "    print(tokens)\n",
    "    assert len(tokens) == 7\n",
    "    assert tokens[0] == 'ACZSBV'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-notebook",
   "metadata": {},
   "source": [
    "### size of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "amateur-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence_size = 20\n",
    "sentence_size = 800\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-bidder",
   "metadata": {},
   "source": [
    "https://jakevdp.github.io/PythonDataScienceHandbook/01.07-timing-and-profiling.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "classified-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-profit",
   "metadata": {},
   "source": [
    "### long string - 1-char word - 1 option - stackoverflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-speech",
   "metadata": {},
   "source": [
    "assume count for 1 word is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "discrete-injury",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop:51\n",
      "duration 0.003133666999929119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats {'E': 50}\n",
      "length 50\n",
      "nb words 1\n",
      "nb encoded words 1\n",
      "nb possible words 1\n",
      " count: 1\n"
     ]
    }
   ],
   "source": [
    "morse_sentence, stats, tokens = generate_random_morse_sentence(sentence_size, signs='E')\n",
    "print(f'stats {stats}')\n",
    "print(f'length {len(morse_sentence)}')\n",
    "words = ['E'] \n",
    "\n",
    "start = time.perf_counter() \n",
    "%prun res = count_runner(morse_sentence, words, verbose=verbose)\n",
    "##%lprun -f count_runner res = count_runner(morse_sentence, words, verbose=verbose)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-knitting",
   "metadata": {},
   "source": [
    "### long string - 2 1-char words - multiple options - stackoverflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "drawn-simpson",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop:51\n",
      "duration 0.00335969700017813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats {'E': 34, 'T': 16}\n",
      "length 50\n",
      "nb words 2\n",
      "nb encoded words 2\n",
      "nb possible words 2\n",
      " count: 1\n"
     ]
    }
   ],
   "source": [
    "morse_sentence, stats, tokens = generate_random_morse_sentence(sentence_size, signs='ET')\n",
    "print(f'stats {stats}')\n",
    "print(f'length {len(morse_sentence)}')\n",
    "words = ['E', 'T'] \n",
    "\n",
    "start = time.perf_counter()\n",
    "%prun res = count_runner(morse_sentence, words, verbose=verbose)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-region",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "built-shuttle",
   "metadata": {},
   "source": [
    "### long string - few words - multiple options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-quick",
   "metadata": {},
   "source": [
    "issue = a large number of words ':' -> execeed recursion limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "amazing-trader",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop:81\n",
      "duration 0.004060274000039499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats {'E': 400}\n",
      "length 400\n",
      "nb words 1\n",
      "nb words 1\n",
      "nb encoded words 1\n",
      "nb possible words 1\n",
      " count: 1\n"
     ]
    }
   ],
   "source": [
    "morse_sentence, stats, tokens = generate_random_morse_sentence(sentence_size, signs='E', chunk_size=5)\n",
    "print(f'stats {stats}')\n",
    "print(f'length {len(morse_sentence)}')\n",
    "words = tokens\n",
    "print(f'nb words {len(words)}')\n",
    "\n",
    "start = time.perf_counter()\n",
    "%prun res = count_runner(morse_sentence, words, verbose=verbose)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res >= 1 # 1 si multiple 2 ou 4 sinon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-second",
   "metadata": {},
   "source": [
    "### long string - more words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "current-inquiry",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop:139\n",
      "total duration 0.026160770999922534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats {'A': 29, 'B': 25, 'C': 38, 'D': 20, 'E': 32, 'F': 31, 'G': 30, 'H': 26, 'I': 31, 'J': 30, 'K': 34, 'L': 32, 'M': 31, 'N': 31, 'O': 32, 'P': 35, 'Q': 37, 'R': 30, 'S': 42, 'T': 31, 'U': 18, 'V': 38, 'W': 33, 'X': 18, 'Y': 34, 'Z': 32}\n",
      "length 2528\n",
      "nb words 134\n",
      "nb words 134\n",
      "nb encoded words 134\n",
      "nb possible words 134\n",
      " count: 1\n"
     ]
    }
   ],
   "source": [
    "morse_sentence, stats, tokens = generate_random_morse_sentence(sentence_size)\n",
    "print(f'stats {stats}')\n",
    "print(f'length {len(morse_sentence)}')\n",
    "words = tokens\n",
    "print(f'nb words {len(words)}')\n",
    "\n",
    "start = time.perf_counter()\n",
    "%prun res = count_runner(morse_sentence, words, verbose=verbose)\n",
    "stop = time.perf_counter()\n",
    "print(f\"total duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res >= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-syndication",
   "metadata": {},
   "source": [
    "### long string - few words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "incoming-january",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loop:16\n",
      "duration 0.004061856000134867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats {'E': 34, 'T': 16}\n",
      "length 50\n",
      "nb words 8\n",
      "nb words 8\n",
      "nb encoded words 8\n",
      "nb possible words 8\n",
      " count: 2\n"
     ]
    }
   ],
   "source": [
    "morse_sentence, stats, tokens = generate_random_morse_sentence(sentence_size, signs='ET')\n",
    "print(f'stats {stats}')\n",
    "print(f'length {len(morse_sentence)}')\n",
    "words = tokens\n",
    "print(f'nb words {len(words)}')\n",
    "\n",
    "start = time.perf_counter()\n",
    "%prun res = count_runner(morse_sentence, words, verbose=verbose)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res >= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-heart",
   "metadata": {},
   "source": [
    "### long sentence - lots of permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "requested-workshop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats {'E': 23, 'I': 11, 'S': 7, 'H': 9}\n",
      "length 102\n",
      "nb words 9\n",
      "nb words 9\n",
      "nb encoded words 7\n",
      "nb possible words 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-516275b632a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prun'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'res = count_runner(morse_sentence, words, verbose=verbose)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"duration {stop-start}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dependencynet/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2325\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2326\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2327\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2328\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-48>\u001b[0m in \u001b[0;36mprun\u001b[0;34m(self, parameter_s, cell)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dependencynet/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dependencynet/lib/python3.8/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mprun\u001b[0;34m(self, parameter_s, cell)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0marg_str\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0marg_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_with_profiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_with_profiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dependencynet/lib/python3.8/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36m_run_with_profiler\u001b[0;34m(self, code, opts, namespace)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mprof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mprof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0msys_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dependencynet/lib/python3.8/cProfile.py\u001b[0m in \u001b[0;36mrunctx\u001b[0;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-e4608239e755>\u001b[0m in \u001b[0;36mcount_runner\u001b[0;34m(target_sentence, words, verbose)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_encoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_encoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, sentence)\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mdecode_loop\u001b[0;34m(self, nodes, last_nb_options)\u001b[0m\n",
      "\u001b[0;32m~/Documents/2021-01/git-repos/morse-challenge/version-9/node.py\u001b[0m in \u001b[0;36mget_nb_options\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mnb_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mNodeState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHILD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mnb_options\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "morse_sentence, stats, tokens = generate_random_morse_sentence(sentence_size, signs='EISH')\n",
    "print(f'stats {stats}')\n",
    "print(f'length {len(morse_sentence)}')\n",
    "words = tokens\n",
    "print(f'nb words {len(words)}')\n",
    "\n",
    "start = time.perf_counter()\n",
    "verbose = False\n",
    "%prun res = count_runner(morse_sentence, words, verbose=verbose)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res >= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-colleague",
   "metadata": {},
   "source": [
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-witch",
   "metadata": {},
   "source": [
    "## long sentence - with repeating pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_sentence = '.-.-.-.-.-.-.-.-' # ETETETETETETETET\n",
    "words = ['E', 'T'] \n",
    "\n",
    "start = time.perf_counter()\n",
    "res = count_runner(morse_sentence, words, verbose=True)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "print(f'count: {res}')\n",
    "\n",
    "assert res == 1 # HELLO WORLD, HELL OWORLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-headquarters",
   "metadata": {},
   "source": [
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-juvenile",
   "metadata": {},
   "source": [
    "# many words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_words(nb, max_length=20, signs=None, seed=1234):\n",
    "    random.seed(seed)\n",
    "    words = []\n",
    "    \n",
    "    for i in range(nb):\n",
    "        current_token = []\n",
    "        size = random.randint(0, 4) + random.randint(0, max_length)\n",
    "\n",
    "        #if not signs: signs = list(alphabet_map.keys())\n",
    "        #max_sign = len(signs) -1\n",
    "        #for s in signs:\n",
    "        #    stats[s] = 0\n",
    "        for i in range(size):\n",
    "            letter = random.randint(0, 25)\n",
    "            current_token.append('ABCDEFGHIJKLMNOPQRSTUVWXYZ'[letter])\n",
    "            #stats[letter] += 1\n",
    "        words.append(''.join(current_token))\n",
    "         \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_map = morse.get_encoded_letters_map()\n",
    "nb = 10000\n",
    "\n",
    "start = time.perf_counter()\n",
    "words = generate_words(nb, seed=1234)\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)\n",
    "\n",
    "assert len(words) == nb\n",
    "print(words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "lengths = {w:len(w) for w in words}\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "for w in words:\n",
    "    n = lengths[w]\n",
    "stop = time.perf_counter()\n",
    "print(f\"duration {stop-start}\", file=sys.stderr, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-survey",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
